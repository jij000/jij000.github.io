<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My Blog</title>
    <link>https://blog.ykeeps.com/</link>
    <description>Recent content on My Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://blog.ykeeps.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Junit</title>
      <link>https://blog.ykeeps.com/post/junit.html</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/junit.html</guid>
      <description>https://www.ibm.com/developerworks/cn/java/j-introducing-junit5-part1-jupiter-api/index.html JUnit Jupiter 是使用 JUnit 5 编写测试内容的 API。JUnit 5 是一个项目名称（和版本），其 3 个主要模块关注不同的方面：JUnit Jupiter、JUnit Platform 和 JUnit Vintage。
Anntation @Test @BeforeEach @BeforeAll @AfterEach @AfterAll Assertions.xxx() @MockBean @SpyBean</description>
    </item>
    
    <item>
      <title>The process of creating a blog system</title>
      <link>https://blog.ykeeps.com/post/the-process-of-creating-a-blog-system.html</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/the-process-of-creating-a-blog-system.html</guid>
      <description>Key function  支持 markdown Angular / React 做界面 MySQL 保存数据 build on Kubernetes Junit 测试 Jenkins CI/CD micro service  user service blog comment Kafka 消息队列接受评论, 审核后发布 wiki 系统    Windows下安装minikube minikube使用帮助(https://kubernetes.io/docs/setup/learning-environment/minikube/) 安装Minikube
# To access the Kubernetes Dashboard, run this command in a shell after starting Minikube to get the address minikube dashboard # To access a Service exposed via a node port, run this command in a shell after starting Minikube to get the address minikube service [-n NAMESPACE] [--url] NAME design domain  micro service  user post comment    参照MangoDB的官方示例 https://www.</description>
    </item>
    
    <item>
      <title>Kafka</title>
      <link>https://blog.ykeeps.com/post/kafka.html</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/kafka.html</guid>
      <description>https://yq.aliyun.com/articles/31546 【笔记】Apache kafka实战 【快速入门】 Kafka入门 https://github.com/ZhongFuCheng3y/3y
Kafka入门 生产者 &amp;amp; 消费者 Kafka是一个消息队列，把消息放到队列里边的叫生产者，从队列里边消费的叫消费者。
topic 一个消息中间件，队列不单单只有一个，我们往往会有多个队列，而我们生产者和消费者就得知道：把数据丢给哪个队列，从哪个队列消息。我们需要给队列取名字，叫做topic(相当于数据库里边表的概念)
现在我们给队列取了名字以后，生产者就知道往哪个队列丢数据了，消费者也知道往哪个队列拿数据了。我们可以有多个生产者往**同一个队列(topic)丢数据，多个消费者往同一个队列(topic)**拿数据
Partition 为了提高一个队列(topic)的吞吐量，Kafka会把topic进行分区(Partition)
所以，生产者实际上是往一个topic名为Java3y中的分区(Partition)丢数据，消费者实际上是往一个topic名为Java3y的分区(Partition)取数据
Broker 一台Kafka服务器叫做Broker，Kafka集群就是多台Kafka服务器：
一个topic会分为多个partition，实际上partition会分布在不同的broker中，举个例子：
由此得知：Kafka是天然分布式的。
备份 现在我们已经知道了往topic里边丢数据，实际上这些数据会分到不同的partition上，这些partition存在不同的broker上。分布式肯定会带来问题：“万一其中一台broker(Kafka服务器)出现网络抖动或者挂了，怎么办？”Kafka是这样做的：我们数据存在不同的partition上，那kafka就把这些partition做备份。比如，现在我们有三个partition，分别存在三台broker上。每个partition都会备份，这些备份散落在不同的broker上。
红色块的partition代表的是主分区，紫色的partition块代表的是备份分区。生产者往topic丢数据，是与主分区交互，消费者消费topic的数据，也是与主分区交互。
高可用 备份分区仅仅用作于备份，不做读写。如果某个Broker挂了，那就会选举出其他Broker的partition来作为主分区，这就实现了高可用。 另外值得一提的是：当生产者把数据丢进topic时，我们知道是写在partition上的，那partition是怎么将其持久化的呢？（不持久化如果Broker中途挂了，那肯定会丢数据嘛)。Kafka是将partition的数据写在磁盘的(消息日志)，不过Kafka只允许追加写入(顺序访问)，避免缓慢的随机 I/O 操作。
 Kafka也不是partition一有数据就立马将数据写到磁盘上，它会先缓存一部分，等到足够多数据量或等待一定的时间再批量写入(flush)。 上面balabala地都是讲生产者把数据丢进topic是怎么样的，下面来讲讲消费者是怎么消费的。既然数据是保存在partition中的，那么消费者实际上也是从partition中取数据。  消费者组 生产者可以有多个，消费者也可以有多个。像上面图的情况，是一个消费者消费三个分区的数据。多个消费者可以组成一个消费者组。
本来是一个消费者消费三个分区的，现在我们有消费者组，就可以每个消费者去消费一个分区（也是为了提高吞吐量）
按图上所示的情况，这里想要说明的是：
 如果消费者组中的某个消费者挂了，那么其中一个消费者可能就要消费两个partition了 如果只有三个partition，而消费者组有4个消费者，那么一个消费者会空闲 如果多加入一个消费者组，无论是新增的消费者组还是原本的消费者组，都能消费topic的全部数据。（消费者组之间从逻辑上它们是独立的） 前面讲解到了生产者往topic里丢数据是存在partition上的，而partition持久化到磁盘是IO顺序访问的，并且是先写缓存，隔一段时间或者数据量足够大的时候才批量写入磁盘的。  消费者高速读, 少做了一步拷贝 消费者在读的时候也很有讲究：正常的读磁盘数据是需要将内核态数据拷贝到用户态的，而Kafka 通过调用sendfile()直接从内核空间（DMA的）到内核空间（Socket的），少做了一步拷贝的操作。
有的同学可能会产生疑问：消费者是怎么知道自己消费到哪里的呀？Kafka不是支持回溯吗？那是怎么做的呀？
 比如上面也提到：如果一个消费者组中的某个消费者挂了，那挂掉的消费者所消费的分区可能就由存活的消费者消费。那存活的消费者是需要知道挂掉的消费者消费到哪了，不然怎么玩。  offset 这里要引出offset了，Kafka就是用offset来表示消费者的消费进度到哪了，每个消费者会都有自己的offset。说白了offset就是表示消费者的消费进度。 在以前版本的Kafka，这个offset是由Zookeeper来管理的，后来Kafka开发者认为Zookeeper不合适大量的删改操作，于是把offset在broker以内部topic(__consumer_offsets)的方式来保存起来。 每次消费者消费的时候，都会提交这个offset，Kafka可以让你选择是自动提交还是手动提交。 既然提到了Zookeeper，那就多说一句。Zookeeper虽然在新版的Kafka中没有用作于保存客户端的offset，但是Zookeeper是Kafka一个重要的依赖。
 探测broker和consumer的添加或移除。 负责维护所有partition的领导者/从属者关系（主分区和备份分区），如果主分区挂了，需要选举出备份分区作为主分区。 维护topic、partition等元配置信息 &amp;hellip;.  最后总结 通过这篇文章，文章开头那几个问题估计多多少少都懂一些啦。我来简要回答一下：
 使用消息队列不可能是单机的（必然是分布式or集群） Kafka天然是分布式的，往一个topic丢数据，实际上就是往多个broker的partition存储数据 数据写到消息队列，可能会存在数据丢失问题，数据在消息队列需要持久化(磁盘？数据库？Redis？分布式文件系统？) Kafka会将partition以消息日志的方式(落磁盘)存储起来，通过 顺序访问IO和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。 想要保证消息（数据）是有序的，怎么做？ Kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。 为什么在消息队列中重复消费了数据 凡是分布式就无法避免网络抖动/机器宕机等问题的发生，很有可能消费者A读取了数据，还没来得及消费，就挂掉了。Zookeeper发现消费者A挂了，让消费者B去消费原本消费者A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了。(各种各样的情况，消费者超时等等都有可能&amp;hellip;) 如果业务上不允许重复消费的问题，最好消费者那端做业务上的校验（如果已经消费过了，就不消费了）  注意学习配置 这篇文章主要是Kafka入门，Kafka还涉及到别的概念，以及还有别的东西。在我感觉中，很多的面试题都跟配置有关，所以在解决某些问题的时候，先看看能不能通过现有配置解决掉（学多了框架，你就会发现很多官方的就已经支持解决了，你做的可能改改配置/参数就完事了）。</description>
    </item>
    
    <item>
      <title>Keywords (Chinese-English)</title>
      <link>https://blog.ykeeps.com/post/keywords-chinese-english.html</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/keywords-chinese-english.html</guid>
      <description>   中文 英文     耦合 couple   松耦合 loosely-coupled   紧耦合 close-coupled   解耦 decouple   异步 asynchronous   同步 synchronous   削峰 limit the number of requests   限流 limit the number of requests   并发 parallel   敏捷 agile    </description>
    </item>
    
    <item>
      <title>ELK</title>
      <link>https://blog.ykeeps.com/post/elk.html</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/elk.html</guid>
      <description>https://www.elastic.co/cn/what-is/elk-stack
“ELK”是三个开源项目的首字母缩写，这三个项目分别是：Elasticsearch、Logstash 和 Kibana。Elasticsearch 是一个搜索和分析引擎。Logstash 是服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到诸如 Elasticsearch 等“存储库”中。Kibana 则可以让用户在 Elasticsearch 中使用图形和图表对数据进行可视化。
Elastic Stack 是 ELK Stack 的更新换代产品。</description>
    </item>
    
    <item>
      <title>SOAP</title>
      <link>https://blog.ykeeps.com/post/soap.html</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/soap.html</guid>
      <description>SOAP (Simple Object Access Protocol) https://searchapparchitecture.techtarget.com/definition/SOAP-Simple-Object-Access-Protocol
 SOAP 基于 XML 格式, 使用Http发送(或者其他网络协议) REST 可以用各种格式, 只用HTTP传输, 使用GET, PUT, POST and DELETE 方法来区分数据的操作  </description>
    </item>
    
    <item>
      <title>Spring Boot</title>
      <link>https://blog.ykeeps.com/post/spring-boot.html</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/spring-boot.html</guid>
      <description>CommandLineRunner  当SpringApplication启动后，我们希望执行某些代码，这是可以通过实现ApplicationRunner或CommandLineRunner接口来实现我们的需求。两个接口的工作方式相同，并且都提供了一个run方法，该方法将在SpringApplication.run(…​)完成之后被调用。  @SpringBootApplicationpublic class SampleSimpleApplication implements CommandLineRunner {@Overridepublic void run(String... args) { // 执行完main 后会执行这个方法 System.out.println(&amp;#34;hello world&amp;#34;);}public static void main(String[] args) throws Exception {SpringApplication.run(SampleSimpleApplication.class, args);}} 当有多个CommandLineRunner的实现时，可以通过实现　Ordered接口来定义调用顺序。代码如下。  import org.springframework.boot.CommandLineRunner;import org.springframework.core.Ordered;import org.springframework.stereotype.Component;@Componentpublic class HelloCommandLine implements CommandLineRunner,Ordered{@Overridepublic void run(String... args) throws Exception {System.out.println(this.getClass().getName());}@Overridepublic int getOrder() {return 11; // 数字越小优先执行 }}</description>
    </item>
    
    <item>
      <title>Docker</title>
      <link>https://blog.ykeeps.com/post/docker.html</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/docker.html</guid>
      <description>常用命令 docker pull nginx # 拉取镜像docker run -d -p 8080:80 nginx # 运行容器, -d 后台运行, -p 主机端口 : 容器端口 做映射docker run -d -P nginx # 运行容器, -d 后台运行, -P 容器的所有端口和主机随机的端口映射, docker ps 可以看到映射的情况docker images # 查看现有镜像docker ps # 查看正在运行的容器docker run --help # 查看帮助docker exec --help # 进入容器内部docker exec -it 03 bash # 进入容器内部, 打开一个容器终端, 03是容器id的开头部分exit # 退出容器终端docker stop 1f #关闭容器docker restart 1f #重启容器which nginx # 查找nginx的安装位置netstat -na|grep 8888 # 查找端口状态uname -a # 查看系统版本制作镜像 Dockerfile</description>
    </item>
    
    <item>
      <title>Hibernate</title>
      <link>https://blog.ykeeps.com/post/hibernate.html</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/hibernate.html</guid>
      <description>Transaction isolation levels https://www.geeksforgeeks.org/transaction-isolation-levels-dbms/ A transaction isolation level is defined by the following phenomena –
 Dirty Read – A Dirty read is the situation when a transaction reads a data that has not yet been committed. For example, Let’s say transaction 1 updates a row and leaves it uncommitted, meanwhile, Transaction 2 reads the updated row. If transaction 1 rolls back the change, transaction 2 will have read data that is considered never to have existed.</description>
    </item>
    
    <item>
      <title>Kubernetes</title>
      <link>https://blog.ykeeps.com/post/kubernetes.html</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/kubernetes.html</guid>
      <description>https://kubernetes.io/docs/setup/learning-environment/minikube/ Kubernetes 指南 详细教程
架构图 kubectl 命令行控制工具
# Health Checkkubectl cluster-infoetcd key value 数据库, 存储集群所有重要配置信息(持久化)
api server 所有服务的统一访问入口
ControllerManager 维持副本期望数
Scheduler 负责接受任务, 选择合适节点进行分配任务
kubelet 直接跟容器引擎交互, 实现容器的生命周期管理
kube-proxy 负责写入规则至 IPTABLES, IPVS实现服务映射访问
Pod 运行容器, 可运行多个 所有Pod在一个可直接连通的扁平的网络空间中
 自主式Pod 控制器管理的Pod  其他插件 CoreDNS 可以为集群中的SVC创建一个域名IP的对应关系解析
Dashboard 给K8S集群一个B/S访问体系
Deploying the Dashboard UI The Dashboard UI is not deployed by default. To deploy it, run the following command:
# 安装 Dashboardkubectl apply -f https://raw.</description>
    </item>
    
    <item>
      <title>Angular</title>
      <link>https://blog.ykeeps.com/post/angular.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/angular.html</guid>
      <description>参考资料 https://coding.imooc.com/class/336.html
环境安装 nodejs npm https://www.npmjs.com/package/@angular/cli
创建工程 # 转到适当文件夹, 创建工程 ng new pingduoduo # 进入工程文件夹, 安装依赖包, 安装在 node_modules 下面 # 无需执行, new 工程时已集成 npm install # 编译并启动服务器, 可预览 ng serve # 检查typescript语法, tslint.json定义了语法规则 ng lint  工程中文件定义     文件名 定义     package.json 每个npm包都会有, 定义了依赖关系   browserslist 定义了支持的浏览器   .editorconfig 编辑器的风格统一   angular.json Angular的配置(项目配置, 编译路径, 输出路径等)    Component (组件) 组件封装 组件输入输出 组件的生命周期 模板在组件类中的引用  开发用工具: https://docs.</description>
    </item>
    
    <item>
      <title>AWS</title>
      <link>https://blog.ykeeps.com/post/aws.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/aws.html</guid>
      <description>EC2 虚拟主机
S3 存储
Lambda 函数计算服务, 无状态
EKS Amazon Elastic Kubernetes Service</description>
    </item>
    
    <item>
      <title>Design Patterns</title>
      <link>https://blog.ykeeps.com/post/design-patterns.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/design-patterns.html</guid>
      <description>Principle 原则 开闭原则  一个软件实体, 如类, 模块, 函数, 应该对扩展开放, 对修改关 面对抽象, 接口编程  依赖倒置原则  高层模块不应该依赖低层模块, 二者都应该依赖其抽象 抽象不应该依赖细节; 细节应该依赖抽象 针对接口编程, 不要针对实现编程  单一职责原则  不要存在多于一个导致类变更的原因 一个类/接口/方法只负责一项职责  接口隔离原则  用多个专门的接口, 而不使用单一的总接口, 客户端不应该依赖它不需要的接口 一个类对一个类的依赖应该建立在最小的接口上 建立单一接口, 不要建立庞大臃肿的接口 尽量细化接口, 接口中的方法尽量少 但是也要有限度  迪米特法则  一个对象应该对其他对象保持最少的了解. 又叫最少知道原则. 尽量降低类与类之间的耦合  里氏替换原则  派生类（子类）对象可以在程式中代替其基类（超类）对象。  合成复用原则 Composite Reuse Principle, CRP  尽量使用对象组合，而不是继承来达到复用的目的。也叫：组合/聚合复用原则 需要慎重使用继承复用  Creational Design Pattern Factory Pattern 工厂模式  简单工厂: 由一个工厂对象决定创建出哪一种产品类的实例   定义一个创建对象的接口, 但让实现这个接口的类来决定实例化哪个类, 工厂方法让类的实例化推迟到子类中进行  Abstract Factory Pattern 抽象工厂模式  提供一个创建一系列相关或者相互依赖对象的接口 无需指定他们具体的类 便于创建产品族, 而工厂模式侧重于创建产品等级  Singleton Pattern 单例模式  保证一个类仅有一个实例, 并提供一个全局访问点 私有构造器 线程安全 延迟加载 序列化和反序列化 反射  Prototype Pattern 原型模式  指原型实例指定创建对象的种类, 并且通过Copy这些原型创建新的对象 注意深克隆和浅克隆  Builder Pattern 建造者模式  将一个复杂对象的构建, 与它的表示分离, 使得同样的构建过程可以创建不同的表示 用户只需指定需要建造的类型就可以得到它们, 建造过程及细节不需要知道  </description>
    </item>
    
    <item>
      <title>EJB</title>
      <link>https://blog.ykeeps.com/post/ejb.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/ejb.html</guid>
      <description>参考资料 EJB到底是什么，真的那么神秘吗？？ EJB Tutorial
EJB 概念  将业务逻辑从客户端软件中抽取出来，封装在一个组件中。这个组件运行在一个独立的服务器上，客户端软件通过网络调用组件提供的服务以实现业务逻辑，而客户端软件的功能单纯到只负责发送调用请求和显示处理结果。 在J2EE 中，这个运行在一个独立的服务器上，并封装了业务逻辑的组件就是EJB（Enterprise JavaBean）组件。 企业开发的逻辑非常复杂, 将业务逻辑抽取出来, 便于组件复用?  EJB 的实现技术 EJB 是运行在独立服务器上的组件，客户端是通过网络对EJB 对象进行调用的。在Java中，能够实现远程对象调用的技术是RMI，而EJB 技术基础正是RMI。通过RMI 技术，J2EE将EJB 组件创建为远程对象，客户端就可以通过网络调用EJB 对象了。
RMI RMI 英文全称是&amp;quot;Remote Method Invocation&amp;rdquo;，它的中文名称是&amp;quot;远程方法调用&amp;rdquo;，它就是利用Java 对象序列化的机制实现分布式计算，实现远程类对象的实例化以及调用的方法。</description>
    </item>
    
    <item>
      <title>Java Core</title>
      <link>https://blog.ykeeps.com/post/java-core.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/java-core.html</guid>
      <description>Java 多线程 异常处理 BIO,NIO,AIO 有什么区别?  BIO (Blocking I/O): 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。 NIO (New I/O): NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发 AIO (Asynchronous I/O): AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。  深拷贝 vs 浅拷贝   浅拷贝：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝，此为浅拷贝。</description>
    </item>
    
    <item>
      <title>Jenkins</title>
      <link>https://blog.ykeeps.com/post/jenkins.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/jenkins.html</guid>
      <description>安装 # 从docker安装docker run -d -u root --name jenkins \ -p 8080:8080 -p 50000:50000 \ -v /root/jenkins_2112:/var/jenkins_home \ jenkins/jenkins:2.112-alpine# 查看admin初始passworddocker exec -it jenkins cat /var/jenkins_home/secrets/initialAdminPassword 安装docker 插件  </description>
    </item>
    
    <item>
      <title>JVM</title>
      <link>https://blog.ykeeps.com/post/jvm.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/jvm.html</guid>
      <description>JVM Framework reflection 反射 Class Loader GC GC策略 GC算法 JVM运行模式 </description>
    </item>
    
    <item>
      <title>New features in Java 8</title>
      <link>https://blog.ykeeps.com/post/new-features-in-java8.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/new-features-in-java8.html</guid>
      <description>Lambda 表达式 Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中。
方法引用 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。
默认方法 默认方法就是一个在接口里面有了一个实现的方法。
Stream API 新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。
Date Time API 加强对日期与时间的处理。
Optional 类 Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。
新工具 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。
Nashorn, JavaScript 引擎 Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。</description>
    </item>
    
    <item>
      <title>Spring Framework</title>
      <link>https://blog.ykeeps.com/post/spring-framework.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.ykeeps.com/post/spring-framework.html</guid>
      <description>Spring的线程安全 Spring 的bean, 默认是 Singleton, 所以并不是线程安全的, 要让Controller之类保持无状态 (不要保存内容), 否则会产生线程安全的问题.
可以用对象锁, ThreadLocal, 声明 scope 为 Request 来解决
https://sylvanassun.github.io/2017/11/06/2017-11-06-spring_and_thread-safe/
Spring对每个bean提供了一个scope属性来表示该bean的作用域。它是bean的生命周期。例如，一个scope为singleton的bean，在第一次被注入时，会创建为一个单例对象，该对象会一直被复用到应用结束。
  singleton：默认的scope，每个scope为singleton的bean都会被定义为一个单例对象，该对象的生命周期是与Spring IOC容器一致的（但在第一次被注入时才会创建）。
  prototype：bean被定义为在每次注入时都会创建一个新的对象。
  request：bean被定义为在每个HTTP请求中创建一个单例对象，也就是说在单个请求中都会复用这一个单例对象。
  session：bean被定义为在一个session的生命周期内创建一个单例对象。
  application：bean被定义为在ServletContext的生命周期中复用一个单例对象。
  websocket：bean被定义为在websocket的生命周期中复用一个单例对象。
  </description>
    </item>
    
  </channel>
</rss>